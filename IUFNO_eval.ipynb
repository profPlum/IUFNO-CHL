{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a816c2-d0bb-4485-ba4b-20ccf08a375e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "IUFNO_path = '/home/cdagrad/dwyerdei/MOR_MoE/IUFNO-CHL'\n",
        "sys.path.append(IUFNO_path)\n",
        "\n",
        "# vor=vorticity\n",
        "#-------------------------------------------------\n",
        "# Dwyer: 21x400x32x33x16x4 (groups, time, x, y, z, channels)\n",
        "# channel flow variables are: u,v,w and p. (these components make up the size_w dim)\n",
        "vor_data = np.load(f'{IUFNO_path}/data_chl_re180/data_mave.npy')\n",
        "n_steps_per_flow_through = int(800/42.5+1-1e-9) # roundup\n",
        "vor_data_small = vor_data[:2,-n_steps_per_flow_through:]\n",
        "#np.save(f'{IUFNO_path}/data_chl_re180/data_mave_small.npy', vor_data_small)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3864418",
      "metadata": {},
      "source": [
        "**Results Summary:**\n",
        "* IUNFO model with reduced dataset size (`weights_IUFNO.pth`): **explodes** well before reaching only 1 flow through!!\n",
        "    * It doesn’t freeze or rather we couldn’t observe a potential freeze because it explodes first.\n",
        "* There was a bug with `data_mave_small.np` preprocessing code that included several flow through times but it still exploded.\n",
        "    * This is why we couldn't possibly train it for the calculated required number of epochs\n",
        "* The paper's original model (`re180_IUFNO.pth`) is stable but of course requires a huge amount of data..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b25505c",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_set_size_mutiplier = (n_steps_per_flow_through/vor_data.shape[1])*(1/(vor_data.shape[0]-1))\n",
        "print(f'{vor_data.shape=}')\n",
        "print(f'{data_set_size_mutiplier=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7583006d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IUFNO import FNO4d\n",
        "\n",
        "modes = 8\n",
        "width = 80\n",
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "weight_decay_value = 1e-11\n",
        "nlayer = 40\n",
        "\n",
        "model = FNO4d(modes, modes, modes, modes, width, nlayer).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ff86a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "paper_model = 're180_IUFNO.pth'\n",
        "our_model = 'weights_IUFNO.pth'\n",
        "model_fn = our_model\n",
        "state_dict = torch.load(f'{IUFNO_path}/{model_fn}')\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d4e13c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "@torch.no_grad()\n",
        "def rollout_autoregressive(model: torch.nn.Module,\n",
        "                           init_frames_np: np.ndarray,\n",
        "                           num_steps: int,\n",
        "                           device = torch.device('cuda')) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Autoregressively predict `num_steps` future frames.\n",
        "    - init_frames_np: [5, X, Y, Z, 3]\n",
        "    Returns: [num_steps, X, Y, Z, 3]\n",
        "    \"\"\"\n",
        "    if init_frames_np.ndim != 5 or init_frames_np.shape[0] != 5 or init_frames_np.shape[-1] != 3:\n",
        "        raise ValueError(f\"Expected init_frames_np as [5, X, Y, Z, 3], got {init_frames_np.shape}\")\n",
        "\n",
        "    window = torch.from_numpy(init_frames_np.astype(np.float32))            # [5, X, Y, Z, 3]\n",
        "    window = window.permute(1, 2, 3, 4, 0).unsqueeze(0).to(device)          # [1, X, Y, Z, 3, 5]\n",
        "\n",
        "    preds = []\n",
        "    for _ in tqdm(range(num_steps)):\n",
        "        delta = model(window)                                               # [1, X, Y, Z, 3, 1]\n",
        "        delta = delta.squeeze(-1)                                           # [1, X, Y, Z, 3]\n",
        "        next_frame = window[..., -1] + delta                                # [1, X, Y, Z, 3]\n",
        "        preds.append(next_frame.squeeze(0).detach().cpu().numpy())\n",
        "        window = torch.cat([window[..., 1:], next_frame.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "    return np.stack(preds, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097fa81a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load initial 5 ground-truth frames from real simulation\n",
        "# Assumes `IUFNO_path` and `model` are already defined above\n",
        "\n",
        "group_index = 0\n",
        "start_timestep = 0\n",
        "\n",
        "# Load full dataset with memory mapping to avoid loading entire file into RAM\n",
        "data_path = f\"{IUFNO_path}/data_chl_re180/data_mave.npy\"\n",
        "vor_data_mem = np.load(data_path, mmap_mode='r')  # [groups, time, X, Y, Z, 4]\n",
        "\n",
        "# Use only u,v,w channels\n",
        "init_frames = vor_data_mem[group_index, start_timestep:start_timestep+5, ..., :3]  # [5, X, Y, Z, 3]\n",
        "print(\"Init frames shape:\", init_frames.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0aa71e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Smoke test: 1-step rollout (quick)\n",
        "assert torch.cuda.is_available(), \"CUDA is required to run the IUFNO model.\"\n",
        "preds_1 = rollout_autoregressive(model, init_frames, num_steps=1)\n",
        "print(\"1-step preds shape:\", preds_1.shape)  # expected: [1, X, Y, Z, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3429f7b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full rollout: 800 steps, then save\n",
        "steps = 800\n",
        "preds_800 = rollout_autoregressive(model, init_frames, num_steps=steps)\n",
        "\n",
        "save_path = f\"{IUFNO_path}/rollout_{steps}.npy\"\n",
        "np.save(save_path, preds_800)\n",
        "print(f\"Saved predictions to: {save_path}\")\n",
        "print(\"Preds shape:\", preds_800.shape)  # expected: [800, X, Y, Z, 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fed003",
      "metadata": {},
      "source": [
        "# Visualize Predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072feb4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from grid_figures import GridFigure\n",
        "import numpy as np\n",
        "\n",
        "# Load predictions if not present in memory\n",
        "if 'preds_800' not in globals():\n",
        "    preds_800 = np.load(f\"{IUFNO_path}/rollout_800.npy\")\n",
        "\n",
        "# preds_800 shape: [T, X, Y, Z, 3]\n",
        "z_idx = preds_800.shape[3] // 2  # middle z-slice\n",
        "max_time = 800\n",
        "max_time = min(max_time, preds_800.shape[0])\n",
        "\n",
        "# Prepare 3D arrays [H, W, T] for each component (u,v,w)\n",
        "u_xyt = np.transpose(preds_800[:max_time, :, :, z_idx, 0], (1, 2, 0))\n",
        "v_xyt = np.transpose(preds_800[:max_time, :, :, z_idx, 1], (1, 2, 0))\n",
        "w_xyt = np.transpose(preds_800[:max_time, :, :, z_idx, 2], (1, 2, 0))\n",
        "\n",
        "fig = GridFigure(title=f\"Predicted u/v/w at z={z_idx} over {max_time} steps\", cmap='bwr')\n",
        "fig.add_3d_row(u_xyt, y_title='u')\n",
        "fig.add_3d_row(v_xyt, y_title='v')\n",
        "fig.add_3d_row(w_xyt, y_title='w')\n",
        "fig_path = f\"{IUFNO_path}/grid_rollout_midZ.png\"\n",
        "fig.show(fig_path=fig_path)\n",
        "print(\"Saved figure:\", fig_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6faa7a2",
      "metadata": {},
      "source": [
        "## Ground Truth vs Prediction Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd207768",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare predicted vs ground-truth (u component) at mid z across selected timesteps\n",
        "import os\n",
        "import numpy as np\n",
        "from grid_figures import GridFigure\n",
        "\n",
        "assert 'preds_800' in globals() or os.path.exists(f\"{IUFNO_path}/rollout_800.npy\"), \"Run the rollout cell first.\"\n",
        "if 'preds_800' not in globals():\n",
        "    preds_800 = np.load(f\"{IUFNO_path}/rollout_800.npy\")\n",
        "\n",
        "# Ensure we have the ground-truth sequence aligned with the rollout start\n",
        "T_pred = preds_800.shape[0]\n",
        "assert 'vor_data_mem' in globals(), \"Reload the dataset cell so vor_data_mem is available.\"\n",
        "\n",
        "gt_seq = vor_data_mem[group_index, start_timestep+5:start_timestep+5+T_pred, ..., :3]\n",
        "T_gt = gt_seq.shape[0]\n",
        "T = min(T_pred, T_gt)\n",
        "if T < T_pred:\n",
        "    preds_800 = preds_800[:T]\n",
        "\n",
        "z_idx = preds_800.shape[3] // 2\n",
        "\n",
        "u_pred_xyt = np.transpose(preds_800[:, :, :, z_idx, 0], (1, 2, 0))  # [H,W,T]\n",
        "u_gt_xyt   = np.transpose(gt_seq[:T, :, :, z_idx, 0], (1, 2, 0))    # [H,W,T]\n",
        "\n",
        "# Sample 10 timesteps across the rollout\n",
        "ncols = 10\n",
        "sample_ts = list(np.linspace(0, T-1, num=ncols, dtype=int))\n",
        "imgs_gt = [u_gt_xyt[:, :, t] for t in sample_ts]\n",
        "imgs_pr = [u_pred_xyt[:, :, t] for t in sample_ts]\n",
        "titles  = [f\"t={start_timestep+5+t}\" for t in sample_ts]\n",
        "\n",
        "# Set symmetric color range using 99th percentile to avoid outliers\n",
        "stack_for_range = np.stack([u_gt_xyt[:, :, sample_ts], u_pred_xyt[:, :, sample_ts]], axis=-1)\n",
        "\n",
        "fig = GridFigure(title=f\"u at z={z_idx}: GT vs Pred\", cmap='bwr')\n",
        "fig.add_img_seq_row(imgs_gt, x_titles=titles, y_title='GT u')\n",
        "fig.add_img_seq_row(imgs_pr, x_titles=titles, y_title='Pred u')\n",
        "fig_path = f\"{IUFNO_path}/grid_rollout_u_midZ_gt_vs_pred.png\"\n",
        "fig.show(fig_path=fig_path)\n",
        "print(\"Saved comparison:\", fig_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b603682b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "uqops",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
